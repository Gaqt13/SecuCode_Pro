import os
from urllib.parse import urlparse
import requests
from bs4 import BeautifulSoup
from flask import Flask, request, jsonify, render_template 
from flask_cors import CORS 
from datetime import datetime
import whois 
import re 

# ----------------------------------------------------
# ğŸ’¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Flask Ù„Ù€ Vercel (Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©):
# ----------------------------------------------------
# Vercel ÙŠØ¨Ø­Ø« ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù† Ù…Ø¬Ù„Ø¯ 'templates' ÙÙŠ Ø§Ù„Ø¬Ø°Ø±.
app = Flask(__name__) 
CORS(app) 
# ----------------------------------------------------


# --- ÙˆØ¸ÙŠÙØ© ÙØ­Øµ Ø³Ù…Ø¹Ø© IP (Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© 7) ---
def check_ip_reputation(domain):
    reputation_points = 0
    try:
        api_url = f"https://api.hackertarget.com/reverseiplookup/?q={domain}"
        response = requests.get(api_url, timeout=3)
        host_count = len(response.text.split('\n'))
        if host_count > 10:
            reputation_points += 2
    except Exception:
        reputation_points += 0 
    return reputation_points

# --- ÙˆØ¸ÙŠÙØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (7 Ù‚ÙˆØ§Ø¹Ø¯ + ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰) ---
def analyze_url(url):
    points = 0
    content_warnings = [] 

    try:
        parsed_url = urlparse(url)
        domain = parsed_url.netloc.lower()
    except ValueError:
        return 10, content_warnings

    # ----------------------------------------------------
    # Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© (ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø·)
    # ----------------------------------------------------
    if len(url) > 70: points += 1
    
    suspicious_keywords = ['login', 'verify', 'update', 'security', 'account', 'paypal', 'bank']
    for keyword in suspicious_keywords:
        if keyword in domain:
            points += 2
            break
            
    if parsed_url.scheme == 'http': points += 3 
    if '@' in url: points += 5 
    if domain.count('.') > 3: points += 1 

    # ÙØ­Øµ Ø¹ÙÙ…Ø± Ø§Ù„Ù†Ø·Ø§Ù‚ (Whois)
    try:
        w = whois.whois(domain)
        today = datetime.now().date()
        creation_date = w.creation_date
        
        if isinstance(creation_date, list): creation_date = creation_date[0]
            
        if creation_date:
            age_in_days = (today - creation_date.date()).days
            if age_in_days < 90: points += 4 
            elif age_in_days < 180: points += 2 
    except Exception: 
        points += 1 

    points += check_ip_reputation(domain)

    # ----------------------------------------------------
    # ğŸ’¡ Ù‚ÙˆØ§Ø¹Ø¯ ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø© (Content Analysis)
    # ----------------------------------------------------
    try:
        response = requests.get(url, timeout=5) 
        response.raise_for_status() 
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 1. ÙØ­Øµ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø­Ø³Ø§Ø³Ø© (Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯)
        password_fields = soup.find_all('input', {'type': 'password'})
        if password_fields and ('login' in url.lower() or 'signin' in url.lower()):
            content_warnings.append("Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø¹ØªÙ…Ø§Ø¯ (ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±).")
            points += 3 
            
        # 2. ÙØ­Øµ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø®ÙÙŠØ© (Iframe / Ø¹Ù†ØµØ± HTML)
        hidden_elements = soup.find_all(lambda tag: tag.has_attr('style') and ('display:none' in tag['style'] or 'visibility:hidden' in tag['style']))
        if hidden_elements:
            content_warnings.append(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(hidden_elements)} Ø¹Ù†ØµØ± HTML/Iframe Ù…Ø®ÙÙŠ (Ù‚Ø¯ ÙŠÙØ³ØªØ®Ø¯Ù… Ù„Ù„Ø³Ø±Ù‚Ø©).")
            points += 2
            
        # 3. ÙØ­Øµ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„ÙÙˆØ±ÙŠØ© (JavaScript Redirect)
        if re.search(r'window\.location|document\.location|header\s*\(\s*["\']location', response.text, re.IGNORECASE):
            content_warnings.append("Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ¬ÙŠÙ‡ ÙÙˆØ±ÙŠØ© (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù„ØµÙØ­Ø© Ø§Ø­ØªÙŠØ§Ù„).")
            points += 2
            
    except requests.exceptions.RequestException:
        content_warnings.append("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø©.")
        points += 1
    except Exception:
        content_warnings.append("Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.")
        points += 1 

    return points, content_warnings 

# ğŸ’¡ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„ØµÙØ­Ø© Ø§Ù„ÙˆÙŠØ¨:
@app.route('/')
def index():
    return render_template('index.html')


# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù€ API
@app.route('/check_link', methods=['POST'])
def check_link():
    data = request.get_json()
    link = data.get('link')

    if not link:
        return jsonify({"error": "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø­Ù‚Ù„ 'link' ÙÙŠ ØµÙŠØºØ© JSON"}), 400

    score, warnings = analyze_url(link)
    
    if score >= 8:
        result = "ğŸ”´ Ø®Ø·Ø± Ø¬Ø³ÙŠÙ… (Ø®Ø·Ø± Ø§Ø­ØªÙŠØ§Ù„ Ù…Ø¤ÙƒØ¯)"
        certainty = "High"
    elif score >= 4:
        result = "ğŸŸ¡ Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡ (ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù…Ø±ÙŠØ¨Ø©)"
        certainty = "Medium"
    else:
        result = "ğŸŸ¢ Ø¢Ù…Ù† Ù†Ø³Ø¨ÙŠØ§Ù‹"
        certainty = "Low"

    return jsonify({
        "link": link,
        "score": score,
        "certainty": certainty,
        "result": result,
        "warnings": warnings 
    })
